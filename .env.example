# OpenAI Configuration (for testing)
USE_OPENAI_FALLBACK=true
OPENAI_ORGANIZATION_ID=org-key
OPENAI_API_KEY=sk-
# Use gpt-4o-mini for true token-by-token streaming (o4-mini is a reasoning model that buffers internally)
OPENAI_MODEL=gpt-5-nano
OPENAI_CHAT_MODEL_ID=gpt-5-nano
PROMPT_COST_PER_1M=0.05
COMPLETION_COST_PER_1M=0.40
OPENAI_IMAGE_RECOGNITION_MODEL=gpt-4.1-nano
OPENAI_IMAGE_RECOGNITION_MODEL_INPUT_COST_PER_1M=0.10
OPENAI_IMAGE_RECOGNITION_MODEL_COMPLETION_COST_PER_1M=0.40
OPENAI_IMAGE_MODEL=gpt-image-1-mini
OPENAI_IMAGE_MODEL_INPUT_COST_PER_1M=2.00
OPENAI_IMAGE_MODEL_COMPLETION_COST_PER_1M=0.20
RATE_LIMIT_PER_MIN=60
LLM_CALL_TIMEOUT=30
# Option 1: OpenAI (Recommended for best quality)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_MODEL=gpt-4o  # or gpt-4o-mini for cost savings
# USE_OPENAI_FALLBACK=true

# Option 2: Ollama (Local models - free but requires local setup)
# USE_OLLAMA=true
# OLLAMA_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1:latest  # or mistral, codellama, etc.

# Option 3: Azure AI Foundry (Enterprise)
# AZURE_AI_PROJECT_ENDPOINT=https://your-project.openai.azure.com
# AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o
# AZURE_OPENAI_API_KEY=your-azure-key-here
# AZURE_OPENAI_API_VERSION=2024-06-01

# Option 4: Microsoft Foundry Local (On-premises)
# USE_FOUNDRY_LOCAL=true
# FOUNDRY_LOCAL_ENDPOINT=http://localhost:8080
# FOUNDRY_LOCAL_MODEL=phi-3-medium


# Application Settings
DEBUG=True
LOG_LEVEL=INFO

